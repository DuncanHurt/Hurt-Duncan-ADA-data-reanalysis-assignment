---
title: "InProgress"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

introductory write-up goes here (mostly exists already as notes in various documents)



## FIRST STEPS
### In this section we create our dataset 'd', which will contain all the data used in the article, with all necessary additions and transformations having been applied so that our data matches what was used in the publication's analyses.
```{r message = FALSE}
#setting up
library(tidyverse)
library(splines)
options(pillar.sigfig = 5)


#creating d0, which holds the original dataset, by reading the prepared csv
d0 <- read_csv("Data\\FantDataSIMPLE.csv")


#creating 'd' by adding a column for the lower bound of the time lag interval
d <- mutate(d0, LAG_MIN = pmax(HIST_DATE - ARCH_DATE_MAX, 0))

#adding a column for the upper bound of the time lag interval
d <- mutate(d, LAG_MAX = pmax(HIST_DATE - ARCH_DATE_MIN, 0))

#adding a column for the overlap variable 'OVLAP', which is 1 when the historical date falls within the archaeological date interval, and 0 when not.
for (i in 1:nrow(d))
{
  if (d[i, "LAG_MIN"] == 0) {d[i, "OVLAP"] <- 1}
  else{d[i, "OVLAP"] <- 0}  
}
  

#Filtering 'd' to only include the 521 cases that are actually used in the publication (will include explanation as to what I'm talking about here in the write-up)
d <- filter(d, ARCH_DATE_MID <= 1600)


#transforming certain variables to match what is done in the publication
d[, "DIST_MAJTOWN"] <- log(d[["DIST_MAJTOWN"]])
d[, "TERR_UNDUL"] <- log(d[["TERR_UNDUL"]])
d[, "DIST_MAJROAD"] <- log(d[["DIST_MAJROAD"]])

d[, "DIST_MONAST"] <- d[["DIST_MONAST"]]/100000
d[, "DIST_PRAGUE"] <- d[["DIST_PRAGUE"]]/100000
d[, "DIST_MAJRIV"] <- d[["DIST_MAJRIV"]]/100000

d[, "LAT"] <- d[["LAT"]]/100000
d[, "LONG"] <- d[["LONG"]]/100000

```




## REPLICATING TABLE 2
```{r}
#preparing to replicate table 2 by selecting/reordering our variables
prep <- select(d, LAG_MIN, LAG_MAX, OVLAP, ARCH_DATE_MID, STATUS, DIST_MAJTOWN, TERR_UNDUL, ALA, DIST_MONAST, DIST_PRAGUE, DIST_MAJRIV, ALTITUDE, LAT, LONG, DIST_MAJROAD)


#creating an empty matrix called 'tab' to hold the values for our replicated table 2
tab <- matrix(data = NA, nrow = 15, ncol = 9)
colnames(tab) <- c("Variable","N", "Mean", "SD", "Min", "Max", "Cor1", "Cor2", "Cor3")


#creating the values for our replicated table 2
for (i in 1:15)
{
  tab[i, 1] <- paste(as.character(i), colnames(prep[i]), sep = ". ")
  tab[i, 2] <- length(prep[[i]][which(!is.na(prep[[i]]))])
  tab[i, 3] <- mean(prep[[i]], na.rm = TRUE)
  tab[i, 4] <- sd(prep[[i]], na.rm = TRUE)
  tab[i, 5] <- min(prep[[i]], na.rm = TRUE)
  tab[i, 6] <- max(prep[[i]], na.rm = TRUE)
  tab[i, 7] <- cor(prep[[1]], prep[[i]], use = "complete.obs")
  tab[i, 8] <- cor(prep[[2]], prep[[i]], use = "complete.obs")
  tab[i, 9] <- cor(prep[[3]], prep[[i]], use = "complete.obs")
}
  
#creating our replicated table 2 by turning 'tab' into a tibble
  (table2 <- as_tibble(tab))
  rm(tab, prep)
```


## REPLICATING SELECTED FIGURES
### This section is still in progress, as I have not figured out how to replicate all the figures (namely, the ones that represent interval values as 'points').
```{r}
  #replicating figures 1A and 2A
 fig1A <- ggplot(d, aes(x=ARCH_DATE_MID, y=OVLAP)) + 
  geom_jitter(size = 4, width = 7, height = 0.01, alpha = 1/5) +
  stat_smooth(color = "black", method="glm", se=TRUE, fullrange = FALSE, method.args = list(family=binomial)) +
  xlim(843, 1607)
 fig1A
  
 fig2A  <- ggplot(d, aes(x=ARCH_DATE_MID, y=OVLAP)) + 
  geom_jitter(size = 4, width = 7, height = 0.01, alpha = 1/5, aes(color = factor(STATUS)))
 fig2A <- fig2A + scale_color_manual(name = "STATUS", values = c("forest green", "blue"))
 fig2A <- fig2A + 
  stat_smooth(data = d[which(d[["STATUS"]] == 1), ], method="glm", se=TRUE, fullrange = FALSE, method.args = list(family=binomial)) +
  stat_smooth(color = "forest green", data = d[which(d[["STATUS"]] == 0), ], method="glm", se=TRUE, fullrange = FALSE, method.args = list(family=binomial)) +
  xlim(843, 1607)
 fig2A
 
 #replicating 3A, which is simpler if we temporarily add a new variable to d
 
 for (i in 1:nrow(d))
{
  if (d[i, "DIST_MAJTOWN"] >= median(d[["DIST_MAJTOWN"]])) {d[i, "bico"] <- 1}
  else{d[i, "bico"] <- 0}  
}
 
 fig3A  <- ggplot(d, aes(x=ARCH_DATE_MID, y=OVLAP)) + 
  geom_jitter(size = 4, width = 7, height = 0.01, alpha = 1/5, aes(color = factor(bico)))
 fig3A <- fig3A + scale_color_manual(name = "distown", values = c("forest green", "blue"))
 fig3A <- fig3A + 
  stat_smooth(data = d[which(d[["DIST_MAJTOWN"]] >= median(d[["DIST_MAJTOWN"]])), ], method="glm", se=TRUE, fullrange = FALSE, method.args = list(family=binomial)) +
  stat_smooth(color = "forest green", data = d[which(d[["DIST_MAJTOWN"]] < median(d[["DIST_MAJTOWN"]])), ], method="glm", se=TRUE, fullrange = FALSE, method.args = list(family=binomial)) +
  xlim(843, 1607)
 fig3A
 d <- select(d, -bico)
```
 
 
## SCRATCHWORK
```{r}
 #Now I am beginning the process of trying to replicate the results shown in table 3
# of the publication. to start, I'm just trying to work out how to calculate
# the value they show in the table, which is the exponentiated coefficient for the
# predictor variable listed in each row. this coefficient comes from a logistic 
# regression model where OVLAP is the response variable and the variable listed in each
# row of table3 is the predictor variable, alongside a natural cubic spline of ARCH_DATE_MID, 
# which was apparently a second predictor variable for every model)

glmfit <- glm(OVLAP ~ STATUS + ns(d[["ARCH_DATE_MID"]], knots = 1250), family = binomial, data = d)
glmfit2 <- glm(OVLAP ~ STATUS + ARCH_DATE_MID, family = binomial, data = d)

#The first line is creating a logistic regression model where the response variable
# y is OVLAP and the predictor variables are STATUS and the natural cubic spline of 
# ARCH_DATE_MID with a knot at 1250. I am not certain if I did it correctly, though.
# the second line does the same thing but with ARCH_DATE_MID un-splined.
``` 

 
  